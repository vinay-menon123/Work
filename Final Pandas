import pandas as pd
import numpy as np
from openpyxl import Workbook
from openpyxl.styles import PatternFill
import time
import chardet
from concurrent.futures import ProcessPoolExecutor
import os
import zipfile
import tempfile
import pyarrow as pa
import pyarrow.parquet as pq
import math

EXCEL_ROW_LIMIT = 1048576  # Excel's max row limit

def detect_encoding(file_path):
    with open(file_path, 'rb') as file:
        raw = file.read(10000)
    return chardet.detect(raw)['encoding']

def process_chunk(chunk_data):
    chunk, columns_to_string, column_b_name, column_c_name, filter_value = chunk_data
    
    for col in columns_to_string:
        if col in chunk.columns:
            chunk[col] = chunk[col].astype(str)

    mask = chunk[column_b_name] == filter_value
    colors = np.zeros(chunk.shape, dtype=bool)
    
    if mask.any():
        for idx, row in chunk[mask].iterrows():
            columns_to_color = str(row[column_c_name]).split(',')
            for col in columns_to_color:
                if col.strip() in chunk.columns:
                    colors[idx, chunk.columns.get_loc(col.strip())] = True

    return chunk.to_numpy(), colors, mask.sum()

def extract_csv_from_zip(zip_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
        if not csv_files:
            raise ValueError("No CSV file found in the ZIP archive")
        
        csv_file = csv_files[0]
        temp_dir = tempfile.mkdtemp()
        extracted_path = zip_ref.extract(csv_file, temp_dir)
        return extracted_path

def save_to_parquet(data, colors, output_parquet):
    df = pd.DataFrame(data, columns=data.columns)
    df['_colors'] = colors.tolist()
    table = pa.Table.from_pandas(df)
    pq.write_table(table, output_parquet, compression='snappy')

def process_input(input_path, output_parquet, columns_to_string, column_b_name, column_c_name, filter_value):
    start_time = time.time()

    if input_path.lower().endswith('.zip'):
        print("ZIP file detected. Extracting CSV...")
        csv_path = extract_csv_from_zip(input_path)
    else:
        csv_path = input_path

    encoding = detect_encoding(csv_path)
    print(f"Detected encoding: {encoding}")

    chunk_size = 1000000
    total_rows = 0
    filtered_rows = 0

    all_data = []
    all_colors = []

    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
        futures = []
        for chunk in pd.read_csv(csv_path, chunksize=chunk_size, encoding=encoding, low_memory=False):
            chunk_data = (chunk, columns_to_string, column_b_name, column_c_name, filter_value)
            futures.append(executor.submit(process_chunk, chunk_data))

        for future in futures:
            data, colors, filtered_count = future.result()
            all_data.append(data)
            all_colors.append(colors)
            total_rows += len(data)
            filtered_rows += filtered_count

    combined_data = np.vstack(all_data)
    combined_colors = np.vstack(all_colors)

    save_to_parquet(pd.DataFrame(combined_data, columns=chunk.columns), combined_colors, output_parquet)

    print(f"Total rows processed: {total_rows}")
    print(f"Rows matching filter: {filtered_rows}")

    if input_path.lower().endswith('.zip'):
        os.remove(csv_path)
        os.rmdir(os.path.dirname(csv_path))

    end_time = time.time()
    print(f"Processing completed in {end_time - start_time:.2f} seconds")

def parquet_to_excel_files(input_parquet, output_base_name):
    start_time = time.time()

    table = pq.read_table(input_parquet)
    df = table.to_pandas()

    colors = df['_colors'].tolist()
    df = df.drop('_colors', axis=1)

    total_rows = len(df)
    num_files = math.ceil(total_rows / EXCEL_ROW_LIMIT)

    excel_files = []

    for file_num in range(num_files):
        start_row = file_num * EXCEL_ROW_LIMIT
        end_row = min((file_num + 1) * EXCEL_ROW_LIMIT, total_rows)
        
        wb = Workbook()
        ws = wb.active

        # Write header
        for col_num, column_title in enumerate(df.columns, 1):
            ws.cell(row=1, column=col_num, value=column_title)

        # Write data and apply colors
        yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

        for row_num, (_, row) in enumerate(df.iloc[start_row:end_row].iterrows(), 2):
            for col_num, value in enumerate(row, 1):
                cell = ws.cell(row=row_num, column=col_num, value=value)
                if colors[start_row + row_num - 2][col_num-1]:
                    cell.fill = yellow_fill

        excel_file_name = f"{output_base_name}_{file_num + 1}.xlsx"
        wb.save(excel_file_name)
        excel_files.append(excel_file_name)

        print(f"Created Excel file {file_num + 1} of {num_files}")

    end_time = time.time()
    print(f"Excel conversion completed in {end_time - start_time:.2f} seconds")

    return excel_files

def zip_excel_files(excel_files, output_zip):
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file in excel_files:
            zipf.write(file, os.path.basename(file))
            os.remove(file)  # Remove the Excel file after adding it to the zip

    print(f"Excel files zipped to {output_zip}")

if __name__ == "__main__":
    input_path = 'input_file.zip'
    output_parquet = 'output_file.parquet'
    output_base_name = 'output_file'
    output_zip = 'output_excel_files.zip'
    columns_to_string = ['Column1', 'Column2']
    column_b_name = 'ColumnB'
    column_c_name = 'ColumnC'
    filter_value = 'A'

    process_input(input_path, output_parquet, columns_to_string, column_b_name, column_c_name, filter_value)
    excel_files = parquet_to_excel_files(output_parquet, output_base_name)
    zip_excel_files(excel_files, output_zip)
