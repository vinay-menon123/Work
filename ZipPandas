def process_chunk(chunk_data):
    chunk, columns_to_string, column_b_name, column_c_name, filter_value = chunk_data
    
    for col in columns_to_string:
        if col in chunk.columns:
            chunk[col] = chunk[col].astype(str)

    mask = chunk[column_b_name] == filter_value
    colors = np.zeros(chunk.shape, dtype=bool)
    
    if mask.any():
        columns_to_color = chunk.loc[mask, column_c_name].str.split(',', expand=True).stack().unique()
        color_indices = [chunk.columns.get_loc(col) for col in columns_to_color if col in chunk.columns]
        mask_np = mask.to_numpy()
        chunk_np = chunk.to_numpy()
        colors[mask_np[:, np.newaxis], color_indices] = True

    return chunk_np, colors, mask.sum()

# Adjustments in the process_input function to handle combined_data and combined_colors correctly
def process_input(input_path, output_parquet, columns_to_string, column_b_name, column_c_name, filter_value):
    start_time = time.time()

    if input_path.lower().endswith('.zip'):
        print("ZIP file detected. Extracting CSV...")
        csv_path = extract_csv_from_zip(input_path)
    else:
        csv_path = input_path

    encoding = detect_encoding(csv_path)
    print(f"Detected encoding: {encoding}")

    chunk_size = 1000000
    total_rows = 0
    filtered_rows = 0

    all_data = []
    all_colors = []

    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
        futures = []
        for chunk in pd.read_csv(csv_path, chunksize=chunk_size, encoding=encoding, low_memory=False):
            chunk_data = (chunk, columns_to_string, column_b_name, column_c_name, filter_value)
            futures.append(executor.submit(process_chunk, chunk_data))

        for future in futures:
            data, colors, filtered_count = future.result()
            all_data.append(data)
            all_colors.append(colors)
            total_rows += len(data)
            filtered_rows += filtered_count

    combined_data = np.vstack(all_data)
    combined_colors = np.vstack(all_colors)

    save_to_parquet(pd.DataFrame(combined_data, columns=chunk.columns), combined_colors, output_parquet)

    print(f"Total rows processed: {total_rows}")
    print(f"Rows matching filter: {filtered_rows}")

    if input_path.lower().endswith('.zip'):
        os.remove(csv_path)
        os.rmdir(os.path.dirname(csv_path))

    end_time = time.time()
    print(f"Processing completed in {end_time - start_time:.2f} seconds")

# Rest of your code remains unchanged

if __name__ == "__main__":
    input_path = 'input_file.zip'
    output_parquet = 'output_file.parquet'
    output_base_name = 'output_file'
    output_zip = 'output_excel_files.zip'
    columns_to_string = ['Column1', 'Column2']
    column_b_name = 'ColumnB'
    column_c_name = 'ColumnC'
    filter_value = 'A'

    process_input(input_path, output_parquet, columns_to_string, column_b_name, column_c_name, filter_value)
    excel_files = parquet_to_excel_files(output_parquet, output_base_name)
    zip_excel_files(excel_files, output_zip)
